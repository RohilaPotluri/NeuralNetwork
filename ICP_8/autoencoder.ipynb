{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwunL/ViZgN4e2AWMT3Egc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmStb2vHAe3q","executionInfo":{"status":"ok","timestamp":1697754560148,"user_tz":240,"elapsed":24085,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}},"outputId":"7137b9ad-a87f-4782-c43e-5febd4bbf685"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n","Epoch 1/5\n","235/235 [==============================] - 6s 19ms/step - loss: 0.6953 - val_loss: 0.6952\n","Epoch 2/5\n","235/235 [==============================] - 3s 14ms/step - loss: 0.6951 - val_loss: 0.6950\n","Epoch 3/5\n","235/235 [==============================] - 2s 10ms/step - loss: 0.6949 - val_loss: 0.6948\n","Epoch 4/5\n","235/235 [==============================] - 2s 10ms/step - loss: 0.6947 - val_loss: 0.6946\n","Epoch 5/5\n","235/235 [==============================] - 2s 10ms/step - loss: 0.6945 - val_loss: 0.6944\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b81f84eba30>"]},"metadata":{},"execution_count":1}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","\n","# this is the size of our encoded representations\n","encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n","\n","# this is our input placeholder\n","input_img = Input(shape=(784,))\n","# \"encoded\" is the encoded representation of the input\n","encoded = Dense(encoding_dim, activation='relu')(input_img)\n","# \"decoded\" is the lossy reconstruction of the input\n","decoded = Dense(784, activation='sigmoid')(encoded)\n","# this model maps an input to its reconstruction\n","autoencoder = Model(input_img, decoded)\n","# this model maps an input to its encoded representation\n","autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n","from keras.datasets import mnist, fashion_mnist\n","import numpy as np\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n","x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","\n","autoencoder.fit(x_train, x_train,\n","                epochs=5,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))"]}]}