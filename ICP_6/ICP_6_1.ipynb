{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO8kaabRwh343Hm09EFMA6Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDX5xlggZPM1","executionInfo":{"status":"ok","timestamp":1695395034924,"user_tz":300,"elapsed":18411,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}},"outputId":"e2b19ade-1f7b-4935-bec0-5e5484782be4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'\n"],"metadata":{"id":"jw71sF11Zayi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import pandas\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","dataset = pd.read_csv(path_to_csv, header=None).values\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","np.random.seed(155)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))\n"],"metadata":{"id":"4COrByTjZfId","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695397868039,"user_tz":300,"elapsed":9440,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}},"outputId":"56e22a5b-d0a0-4a25-f12d-92375b5185ac"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","18/18 [==============================] - 1s 3ms/step - loss: 5.8476 - acc: 0.3715\n","Epoch 2/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.8740 - acc: 0.6389\n","Epoch 3/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.1807 - acc: 0.6250\n","Epoch 4/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.0536 - acc: 0.6337\n","Epoch 5/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.9651 - acc: 0.6406\n","Epoch 6/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.9001 - acc: 0.6476\n","Epoch 7/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.8538 - acc: 0.6562\n","Epoch 8/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8111 - acc: 0.6615\n","Epoch 9/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7824 - acc: 0.6736\n","Epoch 10/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7633 - acc: 0.6562\n","Epoch 11/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7507 - acc: 0.6719\n","Epoch 12/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7554 - acc: 0.6875\n","Epoch 13/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7414 - acc: 0.6736\n","Epoch 14/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7445 - acc: 0.6736\n","Epoch 15/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7432 - acc: 0.6944\n","Epoch 16/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7201 - acc: 0.6771\n","Epoch 17/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7044 - acc: 0.6823\n","Epoch 18/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.6927\n","Epoch 19/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6762 - acc: 0.7031\n","Epoch 20/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6763 - acc: 0.7014\n","Epoch 21/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.7031\n","Epoch 22/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6791 - acc: 0.7222\n","Epoch 23/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.6962\n","Epoch 24/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.7014\n","Epoch 25/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6610 - acc: 0.7118\n","Epoch 26/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6541 - acc: 0.7101\n","Epoch 27/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6503 - acc: 0.7101\n","Epoch 28/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6474 - acc: 0.7135\n","Epoch 29/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6335 - acc: 0.7205\n","Epoch 30/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6330 - acc: 0.7118\n","Epoch 31/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.6327 - acc: 0.7049\n","Epoch 32/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - acc: 0.7135\n","Epoch 33/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - acc: 0.7118\n","Epoch 34/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.6294 - acc: 0.7083\n","Epoch 35/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6409 - acc: 0.6979\n","Epoch 36/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.6383 - acc: 0.7292\n","Epoch 37/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6536 - acc: 0.6858\n","Epoch 38/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6206 - acc: 0.7257\n","Epoch 39/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6130 - acc: 0.7274\n","Epoch 40/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6153 - acc: 0.7135\n","Epoch 41/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.6085 - acc: 0.7083\n","Epoch 42/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5995 - acc: 0.7292\n","Epoch 43/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6069 - acc: 0.7205\n","Epoch 44/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6001 - acc: 0.7309\n","Epoch 45/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6080 - acc: 0.7135\n","Epoch 46/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5956 - acc: 0.7240\n","Epoch 47/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6028 - acc: 0.7031\n","Epoch 48/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5907 - acc: 0.7188\n","Epoch 49/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5987 - acc: 0.7361\n","Epoch 50/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5956 - acc: 0.7257\n","Epoch 51/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5956 - acc: 0.7292\n","Epoch 52/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5874 - acc: 0.7309\n","Epoch 53/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5914 - acc: 0.7101\n","Epoch 54/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - acc: 0.7222\n","Epoch 55/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5955 - acc: 0.7292\n","Epoch 56/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6100 - acc: 0.7188\n","Epoch 57/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - acc: 0.7326\n","Epoch 58/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - acc: 0.7257\n","Epoch 59/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - acc: 0.7083\n","Epoch 60/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5774 - acc: 0.7274\n","Epoch 61/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5802 - acc: 0.7257\n","Epoch 62/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6020 - acc: 0.7188\n","Epoch 63/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.7205\n","Epoch 64/100\n","18/18 [==============================] - 0s 7ms/step - loss: 0.5846 - acc: 0.7153\n","Epoch 65/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5721 - acc: 0.7066\n","Epoch 66/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6249 - acc: 0.7309\n","Epoch 67/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6079 - acc: 0.7170\n","Epoch 68/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.5720 - acc: 0.7274\n","Epoch 69/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.5849 - acc: 0.7309\n","Epoch 70/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5806 - acc: 0.7222\n","Epoch 71/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5650 - acc: 0.7257\n","Epoch 72/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5584 - acc: 0.7344\n","Epoch 73/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5624 - acc: 0.7240\n","Epoch 74/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - acc: 0.7170\n","Epoch 75/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5724 - acc: 0.7188\n","Epoch 76/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5673 - acc: 0.7361\n","Epoch 77/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5573 - acc: 0.7448\n","Epoch 78/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - acc: 0.7361\n","Epoch 79/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5691 - acc: 0.7344\n","Epoch 80/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5877 - acc: 0.7205\n","Epoch 81/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5776 - acc: 0.7240\n","Epoch 82/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5679 - acc: 0.7083\n","Epoch 83/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - acc: 0.7344\n","Epoch 84/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - acc: 0.7465\n","Epoch 85/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5532 - acc: 0.7448\n","Epoch 86/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5505 - acc: 0.7361\n","Epoch 87/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5563 - acc: 0.7274\n","Epoch 88/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - acc: 0.7344\n","Epoch 89/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - acc: 0.7101\n","Epoch 90/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - acc: 0.7240\n","Epoch 91/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5520 - acc: 0.7292\n","Epoch 92/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5524 - acc: 0.7483\n","Epoch 93/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.7240\n","Epoch 94/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5586 - acc: 0.7396\n","Epoch 95/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - acc: 0.7257\n","Epoch 96/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.7257\n","Epoch 97/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - acc: 0.7257\n","Epoch 98/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - acc: 0.7344\n","Epoch 99/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - acc: 0.7413\n","Epoch 100/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - acc: 0.7361\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 20)                180       \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 201 (804.00 Byte)\n","Trainable params: 201 (804.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6082 - acc: 0.6875\n","[0.6082359552383423, 0.6875]\n"]}]},{"cell_type":"code","source":["import keras\n","import pandas as pd\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from sklearn.model_selection import train_test_split\n","\n","# load dataset\n","path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'\n","dataset = pd.read_csv(path_to_csv, header=None).values\n","\n","# split dataset into training and test sets\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","\n","# define the model\n","np.random.seed(155)\n","my_second_nn = Sequential()\n","my_second_nn.add(Dense(20, input_dim=8, activation='relu'))\n","my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n","my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n","my_second_nn.add(Dense(1, activation='sigmoid'))\n","my_second_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# train the model\n","my_second_nn_fitted= my_second_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","\n","\n","# evaluate the model on the test set\n","score = my_second_nn.evaluate(X_test, Y_test, batch_size=64)\n","print(my_second_nn.summary())\n","print(\"Test accuracy:\", score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCeESYqDl1Cm","executionInfo":{"status":"ok","timestamp":1695397943932,"user_tz":300,"elapsed":6096,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}},"outputId":"c3401958-64dc-43c3-c651-4b3ef5cc9d34"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","18/18 [==============================] - 1s 1ms/step - loss: 3.1522 - accuracy: 0.5799\n","Epoch 2/100\n","18/18 [==============================] - 0s 1ms/step - loss: 1.1203 - accuracy: 0.6250\n","Epoch 3/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.8774 - accuracy: 0.6233\n","Epoch 4/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7584 - accuracy: 0.6580\n","Epoch 5/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.6128\n","Epoch 6/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6545\n","Epoch 7/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6354\n","Epoch 8/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.6441\n","Epoch 9/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.6545\n","Epoch 10/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6597\n","Epoch 11/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6580\n","Epoch 12/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6684\n","Epoch 13/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.6997\n","Epoch 14/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7677 - accuracy: 0.6458\n","Epoch 15/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6545\n","Epoch 16/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7118\n","Epoch 17/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.6910\n","Epoch 18/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6944\n","Epoch 19/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6736\n","Epoch 20/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.7205\n","Epoch 21/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.6997\n","Epoch 22/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.6823\n","Epoch 23/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6132 - accuracy: 0.7205\n","Epoch 24/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6910\n","Epoch 25/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7175 - accuracy: 0.6753\n","Epoch 26/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.6753\n","Epoch 27/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6771\n","Epoch 28/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7118\n","Epoch 29/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7153\n","Epoch 30/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7222\n","Epoch 31/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7101\n","Epoch 32/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7118\n","Epoch 33/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7083\n","Epoch 34/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7257\n","Epoch 35/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7031\n","Epoch 36/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6067 - accuracy: 0.6997\n","Epoch 37/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6910\n","Epoch 38/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.7066\n","Epoch 39/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7188\n","Epoch 40/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7309\n","Epoch 41/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6892\n","Epoch 42/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7205\n","Epoch 43/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7396\n","Epoch 44/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7188\n","Epoch 45/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7326\n","Epoch 46/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7240\n","Epoch 47/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7361\n","Epoch 48/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7413\n","Epoch 49/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.7135\n","Epoch 50/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.7049\n","Epoch 51/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7431\n","Epoch 52/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7222\n","Epoch 53/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7083\n","Epoch 54/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7257\n","Epoch 55/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7031\n","Epoch 56/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7326\n","Epoch 57/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7222\n","Epoch 58/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7274\n","Epoch 59/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7066\n","Epoch 60/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7378\n","Epoch 61/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7483\n","Epoch 62/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7188\n","Epoch 63/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7101\n","Epoch 64/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7274\n","Epoch 65/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6719\n","Epoch 66/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7170\n","Epoch 67/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.7465\n","Epoch 68/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7413\n","Epoch 69/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.7309\n","Epoch 70/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7240\n","Epoch 71/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7413\n","Epoch 72/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7118\n","Epoch 73/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7170\n","Epoch 74/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7604\n","Epoch 75/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7483\n","Epoch 76/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7448\n","Epoch 77/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.7222\n","Epoch 78/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7031\n","Epoch 79/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7240\n","Epoch 80/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7309\n","Epoch 81/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7500\n","Epoch 82/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7361\n","Epoch 83/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7483\n","Epoch 84/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7205\n","Epoch 85/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7448\n","Epoch 86/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.7101\n","Epoch 87/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7361\n","Epoch 88/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7257\n","Epoch 89/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.7378\n","Epoch 90/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.8029 - accuracy: 0.6788\n","Epoch 91/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7257\n","Epoch 92/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7118\n","Epoch 93/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7465\n","Epoch 94/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7465\n","Epoch 95/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7396\n","Epoch 96/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7431\n","Epoch 97/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7552\n","Epoch 98/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7396\n","Epoch 99/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7326\n","Epoch 100/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7361\n","3/3 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6719\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 20)                180       \n","                                                                 \n"," dense_3 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_4 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 1041 (4.07 KB)\n","Trainable params: 1041 (4.07 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Test accuracy: 0.671875\n"]}]},{"cell_type":"code","source":["path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/breastcancer.csv'\n"],"metadata":{"id":"teGrKeBjl9GN","executionInfo":{"status":"ok","timestamp":1695397962855,"user_tz":300,"elapsed":140,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Load dataset\n","data = load_breast_cancer()\n","\n","# Split dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,\n","                                                    test_size=0.25, random_state=87)\n","\n","# Normalize data\n","sc = StandardScaler()\n","X_train_norm = sc.fit_transform(X_train)\n","X_test_norm = sc.transform(X_test)\n","\n","# Create model\n","np.random.seed(155)\n","model = Sequential()\n","model.add(Dense(20, input_dim=30, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(X_train_norm, y_train, epochs=100, initial_epoch=0)\n","\n","# Evaluate model on testing set\n","loss, accuracy = model.evaluate(X_test_norm, y_test)\n","print(model.summary())\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgSD0V8fmA_E","executionInfo":{"status":"ok","timestamp":1695397982668,"user_tz":300,"elapsed":4089,"user":{"displayName":"Rohila Potluri","userId":"06590240421645597403"}},"outputId":"b1aed89b-9340-49dd-cc11-52fdfef387ec"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","14/14 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.8850\n","Epoch 2/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.9319\n","Epoch 3/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9366\n","Epoch 4/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9460\n","Epoch 5/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9531\n","Epoch 6/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9577\n","Epoch 7/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9577\n","Epoch 8/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9601\n","Epoch 9/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9624\n","Epoch 10/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9648\n","Epoch 11/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9695\n","Epoch 12/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9695\n","Epoch 13/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9695\n","Epoch 14/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9765\n","Epoch 15/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9765\n","Epoch 16/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9765\n","Epoch 17/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9765\n","Epoch 18/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9765\n","Epoch 19/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9765\n","Epoch 20/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9789\n","Epoch 21/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9836\n","Epoch 22/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9836\n","Epoch 23/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9836\n","Epoch 24/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9836\n","Epoch 25/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9836\n","Epoch 26/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9836\n","Epoch 27/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9859\n","Epoch 28/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9859\n","Epoch 29/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9883\n","Epoch 30/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9883\n","Epoch 31/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9859\n","Epoch 32/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9859\n","Epoch 33/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9859\n","Epoch 34/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9859\n","Epoch 35/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9859\n","Epoch 36/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9859\n","Epoch 37/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9883\n","Epoch 38/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9883\n","Epoch 39/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9883\n","Epoch 40/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9883\n","Epoch 41/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9883\n","Epoch 42/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9883\n","Epoch 43/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9883\n","Epoch 44/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9906\n","Epoch 45/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9906\n","Epoch 46/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9906\n","Epoch 47/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9906\n","Epoch 48/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9906\n","Epoch 49/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9930\n","Epoch 50/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9930\n","Epoch 51/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9930\n","Epoch 52/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9930\n","Epoch 53/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9930\n","Epoch 54/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9930\n","Epoch 55/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9930\n","Epoch 56/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9930\n","Epoch 57/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9930\n","Epoch 58/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9930\n","Epoch 59/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9930\n","Epoch 60/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9930\n","Epoch 61/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9930\n","Epoch 62/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9930\n","Epoch 63/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9930\n","Epoch 64/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9930\n","Epoch 65/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9930\n","Epoch 66/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9930\n","Epoch 67/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9930\n","Epoch 68/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9930\n","Epoch 69/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9930\n","Epoch 70/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9930\n","Epoch 71/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9930\n","Epoch 72/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9930\n","Epoch 73/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9930\n","Epoch 74/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9930\n","Epoch 75/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9930\n","Epoch 76/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9930\n","Epoch 77/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9930\n","Epoch 78/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9930\n","Epoch 79/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9930\n","Epoch 80/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9930\n","Epoch 81/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9930\n","Epoch 82/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9930\n","Epoch 83/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9930\n","Epoch 84/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9930\n","Epoch 85/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9930\n","Epoch 86/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9930\n","Epoch 87/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9930\n","Epoch 88/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9930\n","Epoch 89/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9930\n","Epoch 90/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9930\n","Epoch 91/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9930\n","Epoch 92/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9930\n","Epoch 93/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9930\n","Epoch 94/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9930\n","Epoch 95/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9930\n","Epoch 96/100\n","14/14 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9930\n","Epoch 97/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9930\n","Epoch 98/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9930\n","Epoch 99/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9930\n","Epoch 100/100\n","14/14 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9930\n","5/5 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9650\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 20)                620       \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 641 (2.50 KB)\n","Trainable params: 641 (2.50 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Loss: 0.15327806770801544\n","Accuracy: 0.9650349617004395\n"]}]}]}